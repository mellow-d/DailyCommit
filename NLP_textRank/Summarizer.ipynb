{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xhb_WYrVVLh"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing nltk.clusters\n",
        "# Importing networkx"
      ],
      "metadata": {
        "id": "G9aKGfyJd4JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mj-c_wtZ70J",
        "outputId": "76a2c6ab-6ed3-4820-9bf4-3745d51d3184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read File"
      ],
      "metadata": {
        "id": "PtP4F830d5sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop() \n",
        "    # print(sentences)\n",
        "    \n",
        "    return sentences\n",
        "\n",
        "# read_article(longText.txt)"
      ],
      "metadata": {
        "id": "ebKa5zwyaII4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)"
      ],
      "metadata": {
        "id": "SfMFQyA-aTp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    # Create an empty similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix"
      ],
      "metadata": {
        "id": "6hsamM7ZaZzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(file_name, top_n=5):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    # Step 1 - Read text anc split it\n",
        "    sentences =  read_article(file_name)\n",
        "\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Step 4 - Sort the rank and pick top sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    # Step 5 - Offcourse, output the summarize texr\n",
        "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
        "    print(len(summarize_text))\n",
        "\n",
        "# let's begin\n",
        "generate_summary( \"longText.txt\", 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlWr_h9lafJX",
        "outputId": "d58c2e5c-564f-486d-a603-71446538462b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I got this assignment from National Public Radio’s three-minute fiction piece\n",
            "Occasionally, they’ll have a national contest for three-minute stories\n",
            "These stories need to be read in the space of three minutes: thus, the name Three-Minute Story\n",
            "You get to write one of these! Your story must make sense, though you may not have a lot of time to fill in background material\n",
            "Within this story you can develop setting, character, plot, conflict, dialogue, and any other story element you deem essential\n",
            "The story’s length should be approximately two-three pages, double-spaced\n",
            "This assignment is fairly open,so don’t be afraid to be creative\n",
            "Usually the contest has specific parameters: for one of the rounds one of the characters has to tell a joke and one of the characters has to cry\n",
            "In another round, the entire story had to be in the form of a voice message\n",
            "Indexes of top ranked_sentence order are  [(0.19974203009926528, ['Occasionally,', 'they’ll', 'have', 'a', 'national', 'contest', 'for', 'three-minute', 'stories']), (0.1964020921135683, ['These', 'stories', 'need', 'to', 'be', 'read', 'in', 'the', 'space', 'of', 'three', 'minutes:', 'thus,', 'the', 'name', 'Three-Minute', 'Story']), (0.18049970690403444, ['I', 'got', 'this', 'assignment', 'from', 'National', 'Public', 'Radio’s', 'three-minute', 'fiction', 'piece']), (0.13733392237415706, ['You', 'get', 'to', 'write', 'one', 'of', 'these!', 'Your', 'story', 'must', 'make', 'sense,', 'though', 'you', 'may', 'not', 'have', 'a', 'lot', 'of', 'time', 'to', 'fill', 'in', 'background', 'material']), (0.10789107002818235, ['Within', 'this', 'story', 'you', 'can', 'develop', 'setting,', 'character,', 'plot,', 'conflict,', 'dialogue,', 'and', 'any', 'other', 'story', 'element', 'you', 'deem', 'essential']), (0.0955269149754383, ['Usually', 'the', 'contest', 'has', 'specific', 'parameters:', 'for', 'one', 'of', 'the', 'rounds', 'one', 'of', 'the', 'characters', 'has', 'to', 'tell', 'a', 'joke', 'and', 'one', 'of', 'the', 'characters', 'has', 'to', 'cry']), (0.061625242526333605, ['This', 'assignment', 'is', 'fairly', 'open,so', 'don’t', 'be', 'afraid', 'to', 'be', 'creative']), (0.020979020979020983, ['The', 'story’s', 'length', 'should', 'be', 'approximately', 'two-three', 'pages,', 'double-spaced'])]\n",
            "Summarize Text: \n",
            " Occasionally, they’ll have a national contest for three-minute stories. These stories need to be read in the space of three minutes: thus, the name Three-Minute Story. I got this assignment from National Public Radio’s three-minute fiction piece. You get to write one of these! Your story must make sense, though you may not have a lot of time to fill in background material. Within this story you can develop setting, character, plot, conflict, dialogue, and any other story element you deem essential\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYBI019_hK1x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}